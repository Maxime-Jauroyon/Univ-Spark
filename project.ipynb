{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install praw\n",
    "# !pip install textblob\n",
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/04/20 15:08:03 WARN Utils: Your hostname, DESKTOP-CBR75GN resolves to a loopback address: 127.0.1.1; using 172.21.23.51 instead (on interface eth0)\n",
      "23/04/20 15:08:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/20 15:08:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a SparkContext\n",
    "sc = SparkContext(appName=\"RedditStreamingSentimentAnalysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/Scientific_Programming/testvenv/lib/python3.8/site-packages/pyspark/streaming/context.py:72: FutureWarning: DStream is deprecated as of Spark 3.4.0. Migrate to Structured Streaming.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a StreamingContext with a batch interval of 10 seconds\n",
    "ssc = StreamingContext(sc, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DStream from the socket\n",
    "dstream = ssc.socketTextStream(\"localhost\", 8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to perform sentiment analysis on each message\n",
    "def analyze_sentiment(message):\n",
    "    blob = TextBlob(message)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    if polarity > 0:\n",
    "        sentiment = \"positive\"\n",
    "    elif polarity < 0:\n",
    "        sentiment = \"negative\"\n",
    "    else:\n",
    "        sentiment = \"neutral\"\n",
    "    return (message,sentiment)\n",
    "    # return (sentiment,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment analysis function to each message in the DStream\n",
    "tagged_dstream = dstream.filter(lambda line: len(line) > 0)\\\n",
    "                        .map(lambda message: analyze_sentiment(message))\\\n",
    "                        # .reduceByKey(lambda a, b: a + b)\n",
    "# .flatMap(lambda line: line.split(\" \"))\\\n",
    "# .map(lambda line: line.split(\"|\"))\\\n",
    "\n",
    "# Print the results\n",
    "tagged_dstream.pprint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For debugging purposes (to check if we receive correctly the data)\n",
    "# counts = dstream.flatMap(lambda line: line.split(\" \"))\\\n",
    "#                 .filter(lambda word: len(word) > 0)\\\n",
    "#                 .map(lambda word: (word, 1))\\\n",
    "#                 .reduceByKey(lambda a, b: a + b)\n",
    "# counts.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-04-20 15:08:10\n",
      "-------------------------------------------\n",
      "(\"I'm wondering if anyone has any recommendations for virtual python coding camps for kids? My son has been working through some books and is having success but I wouldn't mind putting him in front of an instructor of some sort as well.\", 'positive')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-04-20 15:08:15\n",
      "-------------------------------------------\n",
      "('Thanks in advance! I mean no offence as I’ve certainly never created a package before - but can you explain how this differs from applying some simple regex? y spoiler tho? Definitely going to have a look at this! Many thanks! There are already a lot of utilities (many of which are built into most operating systems) that do this. Why re-invent the wheel as a third party python package? Thanks for your comment, actually now I’m using regex, the difference now is I’m using also request lib to handle connection and convert it to text, also I’m using KMP algorithm to search for patterns and words.', 'positive')\n",
      "(\"This is the beta version, I will keep adding more algorithms and more features like save in file, analytics and more, but I want to take step one and publish it In case you haven't gotten that far in Python yet In case you mean it is simple, yes it is simple package and I want to add more functionality, features and algorithms, but I want to take a first step and publish it  to know if this kind will be interesting to users or not Thanks, I will be waiting to know your opinion after reviewing it lol No, I mean why did you mark the post as a spoiler? You know there are still people who haven't finished 2.X yet Thank you I fixed it If you’ve got to deal with a very large CSV file, reading it in efficiently is the least of your problems. The bigger challenge is working with it efficiently.\", 'positive')\n",
      "('This section of the pandas documentation talks about techniques ', 'neutral')\n",
      "('https://pandas.pydata.org/docs/user_guide/scale.html', 'neutral')\n",
      "('Its discussion of [dask](https://www.dask.org) helped not only read in but work with a 3 billion row CSV file for me', 'neutral')\n",
      "(\"The author mentioned using a chrome-book, i wonder how something like dask would perform on a chrome-book in actual work with the data they were reading from CSV Interesting study. My data needs are trivial and I'm still learning. I've worked with Pandas enough to have stepped on several of the rakes, so Polars sounds intriguing more from the API standpoint than the need for speed. Either way though, I'm still working out how to break it into intelligible functions rather than chaining as far as the eye can see. Type inference may be very different.\", 'positive')\n",
      "(\"It's hard to judge the speed of things like reading a csv because...\", 'negative')\n",
      "('* Did you want type inference? And if so whose?', 'neutral')\n",
      "(\"* If you didn't want type inference why are you using csv?\", 'neutral')\n",
      "('* If csv reading is a big part of your processing time you will likely optimize this by finding a way to read and parse data in batch to a better format.', 'positive')\n",
      "...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-04-20 15:08:20\n",
      "-------------------------------------------\n",
      "(\"My god... I dunno, I only skimmed the sales pitch when our infosec team asked us to integrate with it. I don't know the pricing model or anything ;) > 12. Strive to make a function not return any arguments\", 'positive')\n",
      "('I do this in OO programming. But this is a big no no in functional programming What a ton of bullpoo from the 90-es!', 'neutral')\n",
      "('> 6. Strive to avoid or minimize the number of function arguments', 'neutral')\n",
      "('> 12. Strive to make a function not return any arguments', 'neutral')\n",
      "(\"== Make sure you can't have even a vague idea what function does until you thoroughly read it through. \", 'neutral')\n",
      "('> 7. Error handling blocks (try/catch) should be placed in separate functions', 'neutral')\n",
      "('== Force stuff into another function just to avoid 1 level of indentation?', 'neutral')\n",
      "('> 9. If possible, replace tests with exception handling', 'neutral')\n",
      "('... and then test the exception handling.', 'neutral')\n",
      "('> 10. Do not return null from a function or pass null as a function argument', 'neutral')\n",
      "...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-04-20 15:08:25\n",
      "-------------------------------------------\n",
      "('Yup :). Thanks! I’ve never heard of loguru before. When I’m not using just the standard lib stuff, I reach for [structlog](https://www.structlog.org/en/stable/). Approachable, can sit right on top of standard logger and has other nifty features too. Never heard of it, is this like \"pretend its super popular and everyone believes its popular\" ? ', 'positive')\n",
      "(\"But then again I am still at from logging import logger Structured logging make it much easier to parse and search logs. Go even introduce an official structured logging package in 1.21: https://www.reddit.com/r/golang/comments/11sdqia/slog\\\\_proposal\\\\_accepted\\\\_for\\\\_go\\\\_121/ reads more like a guerrilla advertising for this library. never heard of it. We use import logging and structlog. I’ve seen it used mostly in production rather than in open source projects. Perhaps this is the answer? People probably find out about it from work/colleagues. Never heard of it. You must be dreaming structlog is very impressive. I'd heard of it, but never looked at the docs in depth. Now I'll take a closer look. I wonder why the default output stream is STDOUT instead of STDERR. 14,000 stars on github... https://github.com/Delgan/loguru\", 'positive')\n",
      "(\"Allegedly it's the most popular third party logging library in Python but structlog is quite attractive. No just some random query into logging based on a work discussion. I would say that 3 years ago I would've reached for structlog after this thread. But take note that loguru has 14k stars on github to structlog 3k fwiw.\", 'positive')\n",
      "(\"I was seriously considering writing a simple wrapper over standard logging but I can see that industrial-strength software like structlog takes serious dedication and talent. And I'm second class in both areas. eh, the standard lib logging is enough for all industry code that I have seen. We use structlog in parallel because one of the devs wanted to get fancy. I have yet to see the payoff. Not saying that structlog is bad. I guess it does what it says.\", 'negative')\n",
      "(\"If I were you, I would just spend the hours and get straight with the standard logging library when need be. It is not so hard. I would recommend you add a “why this” in your README. Maybe describe benefits over using standard GitHub actions configs. What would be the benefit of trying to do github actions in python? The benefit for our team was python, since no one is close familiar with JS/TS I've put together a fairly detailed set of Python Tutorials covering the use of JupyterLab. They should be a good resource for beginners and intermediate Python Programmers.\", 'positive')\n",
      "('* Mambaforge and Python Environments for Spyder and JupyterLab', 'neutral')\n",
      "('* Markdown and LaTeX', 'neutral')\n",
      "('* The Linux Terminal Bash', 'neutral')\n",
      "('* Text Data Types', 'neutral')\n",
      "('* Numeric Data Types', 'neutral')\n",
      "...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-04-20 15:08:30\n",
      "-------------------------------------------\n",
      "('They are not mutually exclusive. Yes, as much as this tutorial adds to anything. Automatic CLI generation from class attributes, ships with a logging attribute, can be configured via CLI or files or OO programming, reactive objects with observers. And it\\'s what ipython is written in. I\\'ve written a few posts at my blog about them, here is one https://may69.com/pros-dont-write-scripts/ tkinter canvas, pyside6 canvas, or, if want it really easy, Turtle. Not sure what kind of geometrical pictures you\\'re thinking of, but if it\\'s solid modeling, look at SolidPython on PyPI. Pillow I use [drawsvg](https://pypi.org/project/drawsvg/) Check out TikZ I swr to god these days anything will get some chatgpt bs thrown at it. \"Combines elements if excel, jupyter notebooks and chatgpt\" what does that even mean? Because of my frustration with pandas, I created op. Is this something anyone else is interested in? I\\'m not quite sure what this is supposed to do and how it\\'s related to pandas They got frustrated with / didn\\'t want to learn Pandas, so they got ChatGPT to write Pandas code. You interface with ChatGPT in Jupyter-like cells and get excel tables as output. ', 'positive')\n",
      "(\"So OP took the worst of all worlds and put a tool they don't know how to use in the middle.\", 'negative')\n",
      "(\"Pandas users don't want excel tables, and excel users won't know Jupyter cells. And I don't trust anyone who uses ChatGPT to make code which they do not know how to evaluate for errors. Smells like a package manager could be in the pipeline? I wouldn't say no to cargo-for-python. First thought: This is so great for the Python ecosystem\", 'positive')\n",
      "(\"Second thought: Man, I really want to learn rust and slowly start to replace Python. mAdE wITh RuSt Im giving that a go in the meantime lol https://github.com/cnpryer/huak There are already noice tools like PDM and poetry for that - would also add Pyflow that is written in rust. I would love he could focus on an existing tool and improve on it rather than creating the n-th one. Poetry has a huge codebase (but eh, I don’t like dependency upper bounds as many others) but also PDM is getting popular Another one? Shouldn't we focus on areas where 0 libraries/tools have been written yet?\", 'positive')\n",
      "(\"Suddenly....I'm having Javascript flashbacks, but don't know why..... Rust is the only language I’ve ever used that I like more than Python. I feel bad saying it in this sub, but I like it a _lot_ more than Python.\", 'positive')\n",
      "('It has a lot of the nicer language advantages that Python does (`for item in myarray` works - who’d have thought?) but unlike Python, I can actually be pretty confident my code works even if I don’t write a test that checks every single line. I learnt Go after I got fed up waiting for them to unfuck Python 3.', 'positive')\n",
      "('A good bit lower level than Python, but dead simple (a better fit for the Tau of Python than Python is these days, tbh). The super-fast compilation and single, static binaries are great, too.', 'positive')\n",
      "(\"They complement each other nicely, imo. Nah, ruff is a legitimate leap forward in the state of the art, not just a re-implementation of some standard UNIX utility. IIRC Large code base like Transformer by HuggingFace is linted with Ruff because of Rust speed. Would you consider letting huak be adopted into Astral? I love huak and would like to see it find more success with a dedicated team behind it. No point of using pdm when the \\\\_\\\\_pypackages\\\\_\\\\_ PEP just got rejected Do you have anything specific you’d be interested in seeing? Rust is good, but when you need a double linked list(my [Theine](https://github.com/Yiling-J/theine) cache package uses that a lot) everything changes. Actually I would recommend Go if you want an alternative. Python 3 was only kinda fucked for 3 years though, honestly. Which is pretty impressive considering the pretty big transition. For sure Why? PDM has always worked with venvs much alike poetry - and that is the default behavior since v2 Do you really need it though? I don't think I've ever seen a linked list that wasn't better as a rope, an array of pointers to an array of pointers, or any number of other data structures that have a tenth of the memory usage and vastly better cache coherence... What’s wrong with the builtin https://doc.rust-lang.org/std/collections/struct.LinkedList.html? Nice! I'm not sure how it would happen, but it seems like they are hiring. I'll root for you if you are thinking of applying. At the risk of sounding like a shill, I did send in some feedback through their contact form and mentioned huak among other things. Then why use pdm over hatch or poetry when it’s less feature complete? I need it because my cache is based on multiple LRU. But I actually store the index number as prev/next, actual data is in a vector. With GIL I don't need to worry about concurrency so it's not very hard to do this. How to use that as LRU cache, does it has MoveToFront method(MoveToFront moves element e to the front of list l. If e is not an element of l, the list is not modified)? I think I should say LRU cache, not double linked list, my fault. Awe thanks! I really appreciate that :) but I should caveat this with huak isnt ready to replace any package managers yet. Its still very raw.\", 'positive')\n",
      "(\"Here’s an issue to track major feature status https://github.com/cnpryer/huak/issues/602 PDM vs Poetry: technically Poetry violates at least one PEP (IIRC 621, metadata specification) but I see why poetry does it and sometimes it is definitely more useful (more like cargo). From other's people experience, the poetry DevX record is not pretty - I was told that poetry released several breaking changes and managing the transition was not straightforward. From my personal testing, up until the last version it was  slower - I reckon now it's basically the same. These are very minor things for me, but might matter more to some?\", 'positive')\n",
      "('Most importantly, though, PDM does not enforce upper boundary constraints. At first I was more \"it\\'s a matter of preference\" thing, but now I consider them more harmful than useful - also in terms of security. It happened more than once at work that we could not promote code because a library \"A\" we depended upon had a dependency \"B\" with a know vulnerability (discovered through dependabot/pip-audit). If \"A\" specified \"B>=<minimum.required.version>\" the fix would be easy. Instead, we could not upgrade to the latest and safe version because \"A\" was managed with poetry and \"B\" was \"\\\\^\"-bounded to the unsafe version, so I had to open an issue in \"A\" to update. Of course, I would have reported it anyway, but we still had to wait until the maintainer fixed the issue.', 'positive')\n",
      "...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-04-20 15:08:35\n",
      "-------------------------------------------\n",
      "('The practical effect is that Streamlit is really great for simple dashboards because it requires very little effort to get things working. What specific issues have you encountered? I quick search I found Unity, Unreal and Blender have graphic generators ', 'positive')\n",
      "(\"I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't \", 'neutral')\n",
      "('render large Jupyter Notebooks, so just in case, here is an ', 'positive')\n",
      "('[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:', 'neutral')\n",
      "('https://nbviewer.jupyter.org/url/github.com/ArtificialIntelligenceToolkit/aitk/blob/master/notebooks/Derivation%20of%20the%20Y-Combinator.ipynb', 'neutral')\n",
      "('Want to run the code yourself? Here is a [binder](https://mybinder.org/) ', 'neutral')\n",
      "('link to start your own Jupyter server and try it out!', 'positive')\n",
      "('https://mybinder.org/v2/gh/ArtificialIntelligenceToolkit/aitk/master?filepath=notebooks%2FDerivation%20of%20the%20Y-Combinator.ipynb', 'neutral')\n",
      "('------', 'neutral')\n",
      "('^(I am a bot.) ', 'neutral')\n",
      "...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-04-20 15:08:40\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maxime/Scientific_Programming/testvenv/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/maxime/Scientific_Programming/testvenv/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-04-20 15:08:45\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m ssc\u001b[39m.\u001b[39mstart()\n\u001b[1;32m      3\u001b[0m \u001b[39m# Wait for the streaming to finish\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m ssc\u001b[39m.\u001b[39;49mawaitTermination()\n",
      "File \u001b[0;32m~/Scientific_Programming/testvenv/lib/python3.8/site-packages/pyspark/streaming/context.py:239\u001b[0m, in \u001b[0;36mStreamingContext.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39mWait for the execution to stop.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39m    time to wait in seconds\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jssc\u001b[39m.\u001b[39;49mawaitTermination()\n\u001b[1;32m    240\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jssc\u001b[39m.\u001b[39mawaitTerminationOrTimeout(\u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m))\n",
      "File \u001b[0;32m~/Scientific_Programming/testvenv/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/Scientific_Programming/testvenv/lib/python3.8/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/Scientific_Programming/testvenv/lib/python3.8/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start the streaming context\n",
    "ssc.start()\n",
    "# Wait for the streaming to finish\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
